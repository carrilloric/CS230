{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Time serie LSTM for Basic DataSet.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2Pmxv2ioyCRw"
      },
      "source": [
        "##### Prototipy de Modelos con LSTM:\n",
        "Univariate Time Series\n",
        " - Baseline\n",
        " - Simple LSTM Model ( One Input )\n",
        "Forecast Multivariate Time Series\n",
        " - Multivariate Single Step Model\n",
        " - MuLtivariate Multiple Step Model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pa49bUnKyRgF"
      },
      "source": [
        "# Time series forecasting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GU8C5qm_4vZb"
      },
      "source": [
        "Packages calls, mount google drive, Tensorflow Backend, Maplotlib, numpy, os, pandas\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7rZnJaGTWQw0",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "mpl.rcParams['figure.figsize'] = (8, 6)\n",
        "mpl.rcParams['axes.grid'] = False\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "root_path = 'gdrive/My Drive/Colab Notebooks/CS230_PROJECT' "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TokBlnUhWFw9"
      },
      "source": [
        "## The Price Stock Dataset\n",
        "We use Sharadar Core US bundle Bundle, specifically implement the tables: Sharadar Equity Prices, Daily Metrics and Core US Fundamentals. These provide daily open/close prices, enterprise value over earnings (evebit), price to book value(pb), price to earnings(pe), volume and trailing 12 months for financial and fundamental data for each stock."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TX6uGeeeWIkG",
        "colab": {}
      },
      "source": [
        "#df = pd.read_csv(csv_path)\n",
        "df = pd.read_csv('gdrive/My Drive/Colab Notebooks/CS230_PROJECT/symbol_Basic.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VdbOWXiTWM2T"
      },
      "source": [
        "Let's take a glance at the data and size."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ojHE-iCCWIhz",
        "colab": {}
      },
      "source": [
        "df.head"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zi4JPAaeBJxS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qfbpcV0MWQzl"
      },
      "source": [
        "As you can see above, we have 1467 day of data for our. This is our Basic dataset.\n",
        "\n",
        "The function below returns the above described windows of time for the model to train on. The parameter `history_size` is the size of the past window of information. The `target_size` is how far in the future does the model need to learn to predict. The `target_size` is the label that needs to be predicted."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7AoxQuTrWIbi",
        "colab": {}
      },
      "source": [
        "def univariate_data(dataset, start_index, end_index, history_size, target_size):\n",
        "  data = []\n",
        "  labels = []\n",
        "\n",
        "  start_index = start_index + history_size\n",
        "  if end_index is None:\n",
        "    end_index = len(dataset) - target_size\n",
        "\n",
        "  for i in range(start_index, end_index):\n",
        "    indices = range(i-history_size, i)\n",
        "    # Reshape data from (history_size,) to (history_size, 1)\n",
        "    data.append(np.reshape(dataset[indices], (history_size, 1)))\n",
        "    labels.append(dataset[i+target_size])\n",
        "  return np.array(data), np.array(labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qoFJZmXBaxCc"
      },
      "source": [
        "for this test we use 90% of our dataset as training set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ia-MPAHxbInX",
        "colab": {}
      },
      "source": [
        "TRAIN_SPLIT = np.int(df.shape[0]*0.9)\n",
        "print(TRAIN_SPLIT)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EowWDtaNnH1y"
      },
      "source": [
        "Setting seed to ensure reproducibility."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-x-GgENynHdx",
        "colab": {}
      },
      "source": [
        "tf.random.set_seed(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8YEwr-NoWUpV"
      },
      "source": [
        "## Part 1: Forecast a univariate time series\n",
        "First, you will train a model using only a single feature ( Close Price Stock Value), and use it to make predictions for that value in the future.\n",
        "\n",
        "Let's first extract only the Close Price from the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nbdcnm1_WIY9",
        "colab": {}
      },
      "source": [
        "\n",
        "uni_data = df['close']\n",
        "uni_data.index = df['date']\n",
        "uni_data.tail()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "aQB-46MyWZMm"
      },
      "source": [
        "Let's observe how this data looks across time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ftOExwAqWXSU",
        "colab": {}
      },
      "source": [
        "uni_data.plot(subplots=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ejSEiDqBWXQa",
        "colab": {}
      },
      "source": [
        "uni_data = uni_data.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-eFckdUUHWmT"
      },
      "source": [
        "It is important to normalize features before training a neural network. A common way to do so is by subtracting the mean and dividing by the standard deviation of each feature."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mxbIic5TMlxx"
      },
      "source": [
        "Note: The mean and standard deviation should only be computed using the training data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Eji6njXvHusN",
        "colab": {}
      },
      "source": [
        "uni_train_mean = uni_data[:TRAIN_SPLIT].mean()\n",
        "uni_train_std = uni_data[:TRAIN_SPLIT].std()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8Gob1YJYH0cH"
      },
      "source": [
        "Let's normalize the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BO55yRD6H0Dx",
        "colab": {}
      },
      "source": [
        "uni_data = (uni_data-uni_train_mean)/uni_train_std"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gn8A_nrccKtn"
      },
      "source": [
        "We create the data for the univariate model. For part 1, the model will be given the last 60 stock close prices, and needs to learn to predict the temperature at the next time step. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aJJ-T49vWXOZ",
        "colab": {}
      },
      "source": [
        "univariate_past_history = 60\n",
        "univariate_future_target = 1\n",
        "\n",
        "x_train_uni, y_train_uni = univariate_data(uni_data, 0, TRAIN_SPLIT,\n",
        "                                           univariate_past_history,\n",
        "                                           univariate_future_target)\n",
        "x_val_uni, y_val_uni = univariate_data(uni_data, TRAIN_SPLIT, None,\n",
        "                                       univariate_past_history,\n",
        "                                       univariate_future_target)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "aWpVMENsdp0N"
      },
      "source": [
        "This is what the `univariate_data` function returns."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "feDd95XFdz5H",
        "colab": {}
      },
      "source": [
        "print ('Single window of past history')\n",
        "print (x_train_uni.shape)\n",
        "print ('\\n Target Price to predict')\n",
        "print (y_train_uni.shape)\n",
        "print ('x to eval')\n",
        "print (x_val_uni.shape)\n",
        "print ('\\n price to eval')\n",
        "print (y_val_uni.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hni3Jt9OMR1_"
      },
      "source": [
        "Now that the data has been created, let's take a look at a single example. The information given to the network is given in blue, and it must predict the value at the red cross."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qVukM9dRipop",
        "colab": {}
      },
      "source": [
        "def create_time_steps(length):\n",
        "  time_steps = []\n",
        "  for i in range(-length, 0, 1):\n",
        "    time_steps.append(i)\n",
        "  return time_steps"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QQeGvh7cWXMR",
        "colab": {}
      },
      "source": [
        "def show_plot(plot_data, delta, title):\n",
        "  labels = ['History', 'True Future', 'Model Prediction']\n",
        "  marker = ['.-', 'rx', 'go']\n",
        "  time_steps = create_time_steps(plot_data[0].shape[0])\n",
        "  if delta:\n",
        "    future = delta\n",
        "  else:\n",
        "    future = 0\n",
        "\n",
        "  plt.title(title)\n",
        "  for i, x in enumerate(plot_data):\n",
        "    if i:\n",
        "      plt.plot(future, plot_data[i], marker[i], markersize=10,\n",
        "               label=labels[i])\n",
        "    else:\n",
        "      plt.plot(time_steps, plot_data[i].flatten(), marker[i], label=labels[i])\n",
        "  plt.legend()\n",
        "  plt.xlim([time_steps[0], (future+5)*2])\n",
        "  plt.xlabel('Time-Step')\n",
        "  return plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gj7w3V6Hf6y0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(y_train_uni[1000])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Pd05iV-UWXKL",
        "colab": {}
      },
      "source": [
        "show_plot([x_train_uni[1000], y_train_uni[1000]], 0, 'Sample Example')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "b5rUJ_2YMWzG"
      },
      "source": [
        "### Vanilla Baseline\n",
        "Before proceeding to train a model, let's first set a simple baseline. Given an input point, the baseline method looks at all the history and predicts the next point to be the average of the last 60 observations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "P9nYWcxMMWnr",
        "colab": {}
      },
      "source": [
        "def baseline(history):\n",
        "  return np.mean(history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OAiOVq9olmZ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(x_train_uni[100])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KMcdFYKQMWlm",
        "colab": {}
      },
      "source": [
        "show_plot([x_train_uni[100], y_train_uni[100], baseline(x_train_uni[100])], 0,\n",
        "           'Baseline Prediction Example')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "067m6t8cMakb"
      },
      "source": [
        "Let's see if you can beat this baseline using a recurrent neural network."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "H4crpOcoMlSe"
      },
      "source": [
        "\n",
        "Let's now use `tf.data` to shuffle, batch, and cache the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kk-evkrmMWh9",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 128\n",
        "#BUFFER_SIZE = 10000\n",
        "BUFFER_SIZE = 256\n",
        "\n",
        "train_univariate = tf.data.Dataset.from_tensor_slices((x_train_uni, y_train_uni))\n",
        "train_univariate = train_univariate.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
        "\n",
        "val_univariate = tf.data.Dataset.from_tensor_slices((x_val_uni, y_val_uni))\n",
        "val_univariate = val_univariate.batch(BATCH_SIZE).repeat()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4nagdTRNfPuZ"
      },
      "source": [
        "You will see the LSTM requires the input shape of the data it is being given."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IDbpHosCMWZO",
        "colab": {}
      },
      "source": [
        "simple_lstm_model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.LSTM(16, input_shape=x_train_uni.shape[-2:]),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "simple_lstm_model.compile(optimizer='adam', loss='mae')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6geqvCtiMty",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train_uni.shape[-2:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NOGZtDAqMtSi"
      },
      "source": [
        "Let's make a sample prediction, to check the output of the model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2mPZbIKCMtLR",
        "colab": {}
      },
      "source": [
        "for x, y in val_univariate.take(1):\n",
        "    print(simple_lstm_model.predict(x).shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QYz6RN_mMyau"
      },
      "source": [
        "Let's train the model now. Each epoch will run for 256 steps, instead of the complete training data as normally done."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0opH9xi5MtIk",
        "colab": {}
      },
      "source": [
        "EVALUATION_INTERVAL = 256\n",
        "EPOCHS = 30\n",
        "\n",
        "simple_lstm_model.fit(train_univariate, epochs=EPOCHS,\n",
        "                      steps_per_epoch=EVALUATION_INTERVAL,\n",
        "                      validation_data=val_univariate, validation_steps=50)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ls77OLctjPkR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(simple_lstm_model.predict(x)[0])\n",
        "print(y[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "euyPo_lyNryZ"
      },
      "source": [
        "#### Predict using the simple LSTM model\n",
        "Now that you have trained your simple LSTM, let's try and make a few predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "S2rRLrs8MtGU",
        "colab": {}
      },
      "source": [
        "for x, y in val_univariate.take(3):\n",
        "  plot = show_plot([x[0].numpy(), y[0].numpy(),\n",
        "                    simple_lstm_model.predict(x)[0]], 0, 'Simple LSTM model')\n",
        "  plot.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Q-AVEJyRNvt0"
      },
      "source": [
        "This looks better than the baseline. Now that you have seen the basics, let's move on to part two, where you will work with a multivariate time series."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VlJYi3_HXcw8"
      },
      "source": [
        "## Part 2: Forecast a multivariate time series"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hoxNZ2GM7DPm"
      },
      "source": [
        "Our final dataset considers 117 features. For simplicity, this section considers only 12. The features used are open daily price, high daily price, low daily price, close price, volumen, dividends, ev, evebit, vebitda, marketcap, pb,pe ps.\n",
        "\n",
        "To use more features, add their names to this list."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DphrB7bxSNDd",
        "colab": {}
      },
      "source": [
        "features_considered = ['open', 'high', 'low', 'close', 'volume','dividends', 'ev', 'evebit', 'evebitda', 'marketcap', 'pb', 'pe', 'ps']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IfQUSiJfUpXJ",
        "colab": {}
      },
      "source": [
        "features = df[features_considered]\n",
        "#features.index = df['Date Time']\n",
        "features.index = df['date']\n",
        "features.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qSfhTZi5r15R"
      },
      "source": [
        "Let's have a look at how each of these features vary across time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QdgC8zvGr21X",
        "colab": {}
      },
      "source": [
        "features.plot(subplots=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cqStgZ-O1b3_"
      },
      "source": [
        "As mentioned, the first step will be to normalize the dataset using the mean and standard deviation of the training data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "W7VuNIwfHRHx",
        "colab": {}
      },
      "source": [
        "dataset = features.values\n",
        "data_mean = dataset.mean(axis=0)\n",
        "print(data_mean)\n",
        "data_std = dataset.std(axis=0)\n",
        "print(dataset[0:5])\n",
        "print(dataset.std(axis=0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eJUeWDqploCt",
        "colab": {}
      },
      "source": [
        "print(dataset[1,:])\n",
        "print(dataset[:,3])\n",
        "dataset = (dataset-data_mean)/data_std\n",
        "print(dataset[1,:])\n",
        "print(dataset[:,3])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LyuGuJUgjUK3"
      },
      "source": [
        "### Single step model\n",
        "In a single step setup, the model learns to predict a single point in the future based on some history provided.\n",
        "\n",
        "The below function performs the same windowing task as below, however, here it samples the past observation based on the step size given."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "d-rVX4d3OF86",
        "colab": {}
      },
      "source": [
        "def multivariate_data(dataset, target, start_index, end_index, history_size,\n",
        "                      target_size, step, single_step=False):\n",
        "  data = []\n",
        "  labels = []\n",
        "\n",
        "  start_index = start_index + history_size\n",
        "  if end_index is None:\n",
        "    end_index = len(dataset) - target_size\n",
        "\n",
        "  for i in range(start_index, end_index):\n",
        "    indices = range(i-history_size, i, step)\n",
        "    data.append(dataset[indices])\n",
        "    print(i,i+target_size,indices)\n",
        "    if single_step:\n",
        "      labels.append(target[i+target_size])\n",
        "    else:\n",
        "      labels.append(target[i:i+target_size])\n",
        "\n",
        "  return np.array(data), np.array(labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HlhVGzPhmMYI",
        "colab": {}
      },
      "source": [
        "\n",
        "past_history = 90\n",
        "future_target = 1\n",
        "STEP = 1\n",
        "\n",
        "x_train_single, y_train_single = multivariate_data(dataset, dataset[:, 3], 0,\n",
        "                                                   TRAIN_SPLIT, past_history,\n",
        "                                                   future_target, STEP,\n",
        "                                                   single_step=True)\n",
        "x_val_single, y_val_single = multivariate_data(dataset, dataset[:, 3],\n",
        "                                               TRAIN_SPLIT, None, past_history,\n",
        "                                               future_target, STEP,\n",
        "                                               single_step=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CamMObrwPhnp"
      },
      "source": [
        "Let's look at a single data-point.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_tVKm-ZIPls0",
        "colab": {}
      },
      "source": [
        "print ('Single window of past history : {}'.format(x_train_single[1].shape))\n",
        "print ('Single window of past history y : {}'.format(y_train_single[1].shape))\n",
        "print(y_train_single[0])\n",
        "print ('Single Valuation window: {}'.format(x_val_single[0].shape))\n",
        "print ('Single Valuation window y : {}'.format(y_val_single[0].shape))\n",
        "print(y_train_single[0])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eCWG4xgQ3O6E",
        "colab": {}
      },
      "source": [
        "train_data_single = tf.data.Dataset.from_tensor_slices((x_train_single, y_train_single))\n",
        "train_data_single = train_data_single.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
        "\n",
        "val_data_single = tf.data.Dataset.from_tensor_slices((x_val_single, y_val_single))\n",
        "val_data_single = val_data_single.batch(BATCH_SIZE).repeat()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0aWec9_nlxBl",
        "colab": {}
      },
      "source": [
        "single_step_model = tf.keras.models.Sequential()\n",
        "single_step_model.add(tf.keras.layers.LSTM(50,return_sequences=True,input_shape=x_train_single.shape[-2:]))\n",
        "single_step_model.add(tf.keras.layers.LSTM(50,dropout=0.2))\n",
        "single_step_model.add(tf.keras.layers.Dense(1))\n",
        "\n",
        "single_step_model.compile(optimizer=tf.keras.optimizers.RMSprop(), loss='mae')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oYhUfWjwOPFN"
      },
      "source": [
        "Let's check out a sample prediction."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yY7FodHVOPsH",
        "colab": {}
      },
      "source": [
        "for x, y in val_data_single.take(1):\n",
        "  print(single_step_model.predict(x).shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "U0jnt2l2mwkl",
        "colab": {}
      },
      "source": [
        "single_step_history = single_step_model.fit(train_data_single, epochs=EPOCHS,\n",
        "                                            steps_per_epoch=EVALUATION_INTERVAL,\n",
        "                                            validation_data=val_data_single,\n",
        "                                            validation_steps=50)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-ZAdeAnP5c72",
        "colab": {}
      },
      "source": [
        "def plot_train_history(history, title):\n",
        "  loss = history.history['loss']\n",
        "  val_loss = history.history['val_loss']\n",
        "  \n",
        "  epochs = range(len(loss))\n",
        "\n",
        "  plt.figure()\n",
        "\n",
        "  plt.plot(epochs, loss, 'b', label='Training loss')\n",
        "  plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "  plt.title(title)\n",
        "  plt.legend()\n",
        "\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "l8lBKA-z5yYV",
        "colab": {}
      },
      "source": [
        "plot_train_history(single_step_history,\n",
        "                   'Single Step Training and validation loss')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXL_jP4IUlqE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(x[0][:, 3])\n",
        "print(y[0])\n",
        "print(single_step_model.predict(x)[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DfjrGAlEUp7i"
      },
      "source": [
        "#### Predict a single step future\n",
        "Now that the model is trained, let's make a few sample predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "h1qmPLLVUpuN",
        "colab": {}
      },
      "source": [
        "for x, y in val_data_single.take(3):\n",
        "  plot = show_plot([x[0][:, 3].numpy(), y[0].numpy(),\n",
        "                    single_step_model.predict(x)[0]], 12,\n",
        "                   'Single Step Prediction')\n",
        "  plot.show()\n",
        "  print (val_data_single.take(3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zml1qUKpaRaa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot = show_plot([x[0][:, 1].numpy(), y[0].numpy(),\n",
        "                    single_step_model.predict(x)[4]], 12,\n",
        "                   'Single Step Prediction')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2GnE087bJYSu"
      },
      "source": [
        "### Multi-Step model\n",
        "In a multi-step prediction model, given a past history, the model needs to learn to predict a range of future values. Thus, unlike a single step model, where only a single future point is predicted, a multi-step model predict a sequence of the future.\n",
        "\n",
        "For the multi-step model, the training data again consists of recordings over the past 60 days. The output is 10 predictions. For this task, the dataset needs to be prepared accordingly, thus the first step is just to create it again, but with a different target window."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kZCk9fqyJZqX",
        "colab": {}
      },
      "source": [
        "future_target = 10\n",
        "x_train_multi, y_train_multi = multivariate_data(dataset, dataset[:, 1], 0,\n",
        "                                                 TRAIN_SPLIT, past_history,\n",
        "                                                 future_target, STEP)\n",
        "x_val_multi, y_val_multi = multivariate_data(dataset, dataset[:, 1],\n",
        "                                             TRAIN_SPLIT, None, past_history,\n",
        "                                             future_target, STEP)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LImXPwAGRtWy"
      },
      "source": [
        "Let's check out a sample data-point."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cjR4PJArMOpA",
        "colab": {}
      },
      "source": [
        "train_data_multi = tf.data.Dataset.from_tensor_slices((x_train_multi, y_train_multi))\n",
        "train_data_multi = train_data_multi.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
        "\n",
        "val_data_multi = tf.data.Dataset.from_tensor_slices((x_val_multi, y_val_multi))\n",
        "val_data_multi = val_data_multi.batch(BATCH_SIZE).repeat()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "IZcg8FWpSG8K"
      },
      "source": [
        "Plotting a sample data-point."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ksXKVbwBV7D3",
        "colab": {}
      },
      "source": [
        "def multi_step_plot(history, true_future, prediction):\n",
        "  plt.figure(figsize=(12, 6))\n",
        "  num_in = create_time_steps(len(history))\n",
        "  num_out = len(true_future)\n",
        "\n",
        "  plt.plot(num_in, np.array(history[:, 1]), label='History')\n",
        "  plt.plot(np.arange(num_out)/STEP, np.array(true_future), 'bo',\n",
        "           label='True Future')\n",
        "  if prediction.any():\n",
        "    plt.plot(np.arange(num_out)/STEP, np.array(prediction), 'ro',\n",
        "             label='Predicted Future')\n",
        "  plt.legend(loc='upper left')\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LCQKetflZRMF"
      },
      "source": [
        "In this plot and subsequent similar plots, the history and the future data are sampled every hour."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "R6G8bacQR4w2",
        "colab": {}
      },
      "source": [
        "for x, y in train_data_multi.take(1):\n",
        "  multi_step_plot(x[0], y[0], np.array([0]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XOjz8DzZ4HFS"
      },
      "source": [
        "Two LSTM layers. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "byAl0NKSNBP6",
        "colab": {}
      },
      "source": [
        "multi_step_model = tf.keras.models.Sequential()\n",
        "multi_step_model.add(tf.keras.layers.LSTM(16,\n",
        "                                          return_sequences=True,\n",
        "                                          input_shape=x_train_multi.shape[-2:]))\n",
        "multi_step_model.add(tf.keras.layers.LSTM(8, activation='relu'))\n",
        "#multi_step_model.add(tf.keras.layers.Dense(72))\n",
        "multi_step_model.add(tf.keras.layers.Dense(10))\n",
        "multi_step_model.compile(optimizer=tf.keras.optimizers.RMSprop(clipvalue=1.0), loss='mae')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UvB7zBqVSMyl"
      },
      "source": [
        "Let's see how the model predicts before it trains."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "13_ZWvB9SRlZ",
        "colab": {}
      },
      "source": [
        "for x, y in val_data_multi.take(1):\n",
        "  print (multi_step_model.predict(x).shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7uwOhXo3Oems",
        "colab": {}
      },
      "source": [
        "multi_step_history = multi_step_model.fit(train_data_multi, epochs=EPOCHS,\n",
        "                                          steps_per_epoch=EVALUATION_INTERVAL,\n",
        "                                          validation_data=val_data_multi,\n",
        "                                          validation_steps=50)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UKfQoBjQ5l7U",
        "colab": {}
      },
      "source": [
        "plot_train_history(multi_step_history, 'Multi-Step Training and validation loss')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oDg94-yq4pas"
      },
      "source": [
        "#### Predict a multi-step future\n",
        "Let's now have a look at how well your network has learnt to predict the future."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dt22wq6fyIBU",
        "colab": {}
      },
      "source": [
        "for x, y in val_data_multi.take(3):\n",
        "  multi_step_plot(x[0], y[0], multi_step_model.predict(x)[4])"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}